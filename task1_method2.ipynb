{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Method 2: Searching Similar Claim by Doc2Vec Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ztMH9twsZIaAetU2h3y0jZ",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_raw/train-claims.json\", 'r', encoding='utf8') as data:\n",
    "    tran_data = json.load(data)\n",
    "with open(\"data_raw/dev-claims.json\", 'r', encoding='utf8') as data:\n",
    "    deva_data = json.load(data)\n",
    "with open(\"data_raw/test-claims-unlabelled.json\", 'r', encoding='utf8') as data:\n",
    "    test_data = json.load(data)\n",
    "\n",
    "test_df = pd.read_csv(\"data_processed/test_df_t1.csv\")\n",
    "tran_df = pd.read_csv(\"data_processed/tran_df_t1.csv\")\n",
    "deva_df = pd.read_csv(\"data_processed/deva_df_t1.csv\")\n",
    "evdn_df = pd.read_csv(\"data_processed/evdn_full_df_t1.csv\")\n",
    "\n",
    "test_text = list(test_df[\"claim\"])\n",
    "tran_text = list(tran_df[\"claim\"])\n",
    "deva_text = list(deva_df[\"claim\"])\n",
    "evdn_text = list(evdn_df[\"evidence\"])\n",
    "\n",
    "test_id = list(test_df[\"claim_index\"])\n",
    "tran_id = list(tran_df[\"claim_index\"])\n",
    "deva_id = list(deva_df[\"claim_index\"])\n",
    "evdn_id = list(evdn_df[\"evdn_index\"])\n",
    "\n",
    "tran_deva_text = tran_text + deva_text\n",
    "tran_deva_id = tran_id + deva_id\n",
    "\n",
    "sentences = evdn_text + test_text + deva_text + tran_text\n",
    "tokenized_sent = []\n",
    "for s in list(sentences):\n",
    "    tokenized_sent.append(word_tokenize(s.lower()))\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_sent)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Load Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "PosByiwsLoHG8jLiCQ8kiP",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#model = Doc2Vec(tagged_data, vector_size = 512, window = 2, min_count = 1, epochs = 100, workers = 1)\n",
    "#model.save(\"doc2vec.model\")\n",
    "\n",
    "model = Doc2Vec.load('doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(s1, s2):\n",
    "    return cosine_similarity(model.infer_vector(word_tokenize(s1)).reshape(1, -1), model.infer_vector(word_tokenize(s2)).reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence Retrieval in Development Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most similar claim from training dataset by cosine distance of dec2vec embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for i in range(len(deva_text)):\n",
    "    print(i)\n",
    "    evdn_pred = []\n",
    "    for j in range(len(tran_text)):\n",
    "        score = cosine(deva_text[i], tran_text[j])\n",
    "        evdn_pred.append([tran_deva_id[j], score])\n",
    "    most_match_claim = sorted(evdn_pred, key=(lambda x:x[1]), reverse=True)[0][0]\n",
    "    pred.append(most_match_claim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the evidence of most similar claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "evidence_list = []\n",
    "for key, value in tran_data.items():\n",
    "    index_list.append(int(key.split(\"-\")[1]))\n",
    "    evidence_list.append(value[\"evidences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deva_data_index_list = []\n",
    "for i in deva_data.keys():\n",
    "    deva_data_index_list.append(int(i.split(\"-\")[1]))\n",
    "\n",
    "evdn_pred_list = []\n",
    "for i in range(len(deva_data)):\n",
    "    evidence_list_new = evidence_list[index_list.index(pred[i])]\n",
    "    evidence_list_cleaned = []\n",
    "    for evidence in evidence_list_new:\n",
    "        evidence_list_cleaned.append(int(evidence.split(\"-\")[1]))\n",
    "    evdn_pred_list.append(evidence_list_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evdn_pred_list_new = []\n",
    "evdn_pred_text = []\n",
    "for item in evdn_pred_list:\n",
    "    temp_list1 = []\n",
    "    temp_list2 = []\n",
    "    for value_list in item:\n",
    "        index = value_list\n",
    "        text = evdn_text[index]\n",
    "        temp_list1.append(str(index))\n",
    "        temp_list2.append(str(text))\n",
    "    evdn_pred_list_new.append(\",\".join(temp_list1))\n",
    "    evdn_pred_text.append(\" \".join(temp_list2))\n",
    "\n",
    "result_list = []\n",
    "for i in range(len(evdn_pred_text)):\n",
    "    result_list.append([evdn_pred_list_new[i], evdn_pred_text[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe = pd.DataFrame(result_list)\n",
    "result_dataframe.columns = [\"evidence_id\", \"evidence_text\"]\n",
    "result_dataframe.to_csv(\"evdn_pred/test_evdn_pred_doc2vec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence Retrieval in Testing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most similar claim from training dataset by cosine distance of dec2vec embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for i in range(len(test_text)):\n",
    "    evdn_pred = []\n",
    "    for j in range(len(tran_deva_text)):\n",
    "        score = cosine(test_text[i], tran_deva_text[j])\n",
    "        evdn_pred.append([tran_deva_id[j], score])\n",
    "    most_match_claim = sorted(evdn_pred, key=(lambda x:x[1]), reverse=True)[0][0]\n",
    "    pred.append(most_match_claim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the evidence of most similar claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "evidence_list = []\n",
    "for key, value in tran_data.items():\n",
    "    index_list.append(int(key.split(\"-\")[1]))\n",
    "    evidence_list.append(value[\"evidences\"])\n",
    "for key, value in deva_data.items():\n",
    "    index_list.append(int(key.split(\"-\")[1]))\n",
    "    evidence_list.append(value[\"evidences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_index_list = []\n",
    "for i in test_data.keys():\n",
    "    test_data_index_list.append(int(i.split(\"-\")[1]))\n",
    "\n",
    "evdn_pred_list = []\n",
    "for i in range(len(test_data)):\n",
    "    evidence_list_new = evidence_list[index_list.index(pred[i])]\n",
    "    evidence_list_cleaned = []\n",
    "    for evidence in evidence_list_new:\n",
    "        evidence_list_cleaned.append(int(evidence.split(\"-\")[1]))\n",
    "    evdn_pred_list.append(evidence_list_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evdn_pred_list_new = []\n",
    "evdn_pred_text = []\n",
    "for item in evdn_pred_list:\n",
    "    temp_list1 = []\n",
    "    temp_list2 = []\n",
    "    for value_list in item:\n",
    "        index = value_list\n",
    "        text = evdn_text[index]\n",
    "        temp_list1.append(str(index))\n",
    "        temp_list2.append(str(text))\n",
    "    evdn_pred_list_new.append(\",\".join(temp_list1))\n",
    "    evdn_pred_text.append(\" \".join(temp_list2))\n",
    "\n",
    "result_list = []\n",
    "for i in range(len(evdn_pred_text)):\n",
    "    result_list.append([evdn_pred_list_new[i], evdn_pred_text[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe = pd.DataFrame(result_list)\n",
    "result_dataframe.columns = [\"evidence_id\", \"evidence_text\"]\n",
    "result_dataframe.to_csv(\"evdn_pred/test_evdn_pred_doc2vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "sentence-transformers",
     "source": "PIP"
    },
    {
     "name": "tensorflow-hub",
     "source": "PIP"
    }
   ],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
